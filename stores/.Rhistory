# Sacamos las predicciones sobre los datos de test
predictiones_1.1 <- predict(fit_1.1 , new_data = test_2)
predictiones_1.2 <- predict(fit_1.2 , new_data = test_2)
predictiones_1.3 <- predict(fit_1.3, new_data = test_2)
predictiones_2.1 <- predict(fit_2.1 , new_data = test_2)
predictiones_2.2 <- predict(fit_2.2, new_data = test_2)
predictiones_2.3 <- predict(fit_2.3, new_data = test_2)
submission_template$ID <- 1:nrow(submission_template)
predictiones_1.1$ID <- 1:nrow(predictiones_1.1)
predictiones_1.2$ID <- 1:nrow(predictiones_1.2)
predictiones_1.3$ID <- 1:nrow(predictiones_1.3)
predictiones_2.1$ID <- 1:nrow(predictiones_2.1)
predictiones_2.2$ID <- 1:nrow(predictiones_2.2)
predictiones_2.3$ID <- 1:nrow(predictiones_2.3)
subida <- merge(submission_template,predictiones_2.3, by="ID")
subidafinal = subset(subida, select = -c(ID,price) )
colnames(subidafinal)[2]="price"
write.csv(subidafinal,file='subida21.csv', row.names=FALSE)
##Modelo
lambda = .1
# Ridge
ridge_spec <- linear_reg(penalty = lambda, mixture = 1) %>%
set_engine("glmnet")
# Lasso
lasso_spec <- linear_reg(penalty = lambda, mixture = 0) %>%
set_engine("glmnet")
# Elastic Net (se especifica el parámetro de mixture entre 0 y 1)
# Tomemos un valor de 0.5 para empezar
elastic_net_spec <- linear_reg(penalty = lambda, mixture = .5) %>%
set_engine("glmnet")
# Primera receta
rec_1 <- recipe(price ~ total_rooms + property_type + distancia_universidades +
distancia_bus + distancia_teatros + distancia_policia + distancia_concesionarios +
distancia_banco + distancia_gasolina + distancia_comercial + distancia_talleres +
distancia_parque , data = db) %>%
step_interact(terms = ~ total_rooms:distancia_parque+distancia_universidades:property_type) %>%
step_novel(all_nominal_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
# Segunda receta
rec_2 <- recipe(price ~ total_rooms + property_type + parqueadero + area_universidades +
area_comercial + area_parques + distancia_bus +  distancia_universidades +
distancia_bus + distancia_teatros + distancia_policia , data = db) %>%
step_interact(terms = ~ total_rooms:area_parques+area_universidades:property_type) %>%
step_novel(all_nominal_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
##Preguntas_______
train_2 <- as.data.frame(lapply(train_2, as.double))
test_2 <- as.data.frame(lapply(test_2, as.double))
# Crear un flujo de trabajo que incluye la receta de preprocesamiento y el modelo
workflow_1.1 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(ridge_spec)
workflow_1.2 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(lasso_spec)
workflow_1.3 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(elastic_net_spec)
workflow_2.1 <- workflow() %>%
add_recipe(rec_2) %>%
add_model(ridge_spec)
workflow_2.2 <- workflow() %>%
add_recipe(rec_2) %>%
add_model(lasso_spec)
workflow_2.3 <- workflow() %>%
add_recipe(rec_2) %>%
add_model(elastic_net_spec)
# Entrenamos el primer modelo con los datos de train
fit_1.1 <- workflow_1.1 %>%
fit(data = train_2)
fit_1.2 <- workflow_1.2 %>%
fit(data = train_2)
fit_1.3 <- workflow_1.3 %>%
fit(data = train_2)
fit_2.1 <- workflow_1.1 %>%
fit(data = train_2)
fit_2.2 <- workflow_2.2 %>%
fit(data = train_2)
fit_2.3 <- workflow_1.1 %>%
fit(data = train_2)
# Sacamos las predicciones sobre los datos de test
predictiones_1.1 <- predict(fit_1.1 , new_data = test_2)
predictiones_1.2 <- predict(fit_1.2 , new_data = test_2)
predictiones_1.3 <- predict(fit_1.3, new_data = test_2)
predictiones_2.1 <- predict(fit_2.1 , new_data = test_2)
predictiones_2.2 <- predict(fit_2.2, new_data = test_2)
predictiones_2.3 <- predict(fit_2.3, new_data = test_2)
submission_template$ID <- 1:nrow(submission_template)
predictiones_1.1$ID <- 1:nrow(predictiones_1.1)
predictiones_1.2$ID <- 1:nrow(predictiones_1.2)
predictiones_1.3$ID <- 1:nrow(predictiones_1.3)
predictiones_2.1$ID <- 1:nrow(predictiones_2.1)
predictiones_2.2$ID <- 1:nrow(predictiones_2.2)
predictiones_2.3$ID <- 1:nrow(predictiones_2.3)
subida <- merge(submission_template,predictiones_2.3, by="ID")
subidafinal = subset(subida, select = -c(ID,price) )
colnames(subidafinal)[2]="price"
write.csv(subidafinal,file='subida22.csv', row.names=FALSE)
##Modelo
lambda = .7
# Ridge
ridge_spec <- linear_reg(penalty = lambda, mixture = 1) %>%
set_engine("glmnet")
# Lasso
lasso_spec <- linear_reg(penalty = lambda, mixture = 0) %>%
set_engine("glmnet")
# Elastic Net (se especifica el parámetro de mixture entre 0 y 1)
# Tomemos un valor de 0.5 para empezar
elastic_net_spec <- linear_reg(penalty = lambda, mixture = .5) %>%
set_engine("glmnet")
# Primera receta
rec_1 <- recipe(price ~ total_rooms + property_type + distancia_universidades +
distancia_bus + distancia_teatros + distancia_policia + distancia_concesionarios +
distancia_banco + distancia_gasolina + distancia_comercial + distancia_talleres +
distancia_parque , data = db) %>%
step_interact(terms = ~ total_rooms:distancia_parque+distancia_universidades:property_type) %>%
step_novel(all_nominal_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
# Segunda receta
rec_2 <- recipe(price ~ total_rooms + property_type + parqueadero + area_universidades +
area_comercial + area_parques + distancia_bus +  distancia_universidades +
distancia_bus + distancia_teatros + distancia_policia , data = db) %>%
step_interact(terms = ~ total_rooms:area_parques+area_universidades:property_type) %>%
step_novel(all_nominal_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
##Preguntas_______
train_2 <- as.data.frame(lapply(train_2, as.double))
test_2 <- as.data.frame(lapply(test_2, as.double))
# Crear un flujo de trabajo que incluye la receta de preprocesamiento y el modelo
workflow_1.1 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(ridge_spec)
workflow_1.2 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(lasso_spec)
workflow_1.3 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(elastic_net_spec)
workflow_2.1 <- workflow() %>%
add_recipe(rec_2) %>%
add_model(ridge_spec)
workflow_2.2 <- workflow() %>%
add_recipe(rec_2) %>%
add_model(lasso_spec)
workflow_2.3 <- workflow() %>%
add_recipe(rec_2) %>%
add_model(elastic_net_spec)
# Entrenamos el primer modelo con los datos de train
fit_1.1 <- workflow_1.1 %>%
fit(data = train_2)
fit_1.2 <- workflow_1.2 %>%
fit(data = train_2)
fit_1.3 <- workflow_1.3 %>%
fit(data = train_2)
fit_2.1 <- workflow_1.1 %>%
fit(data = train_2)
fit_2.2 <- workflow_2.2 %>%
fit(data = train_2)
fit_2.3 <- workflow_1.1 %>%
fit(data = train_2)
# Sacamos las predicciones sobre los datos de test
predictiones_1.1 <- predict(fit_1.1 , new_data = test_2)
predictiones_1.2 <- predict(fit_1.2 , new_data = test_2)
predictiones_1.3 <- predict(fit_1.3, new_data = test_2)
predictiones_2.1 <- predict(fit_2.1 , new_data = test_2)
predictiones_2.2 <- predict(fit_2.2, new_data = test_2)
predictiones_2.3 <- predict(fit_2.3, new_data = test_2)
submission_template$ID <- 1:nrow(submission_template)
predictiones_1.1$ID <- 1:nrow(predictiones_1.1)
predictiones_1.2$ID <- 1:nrow(predictiones_1.2)
predictiones_1.3$ID <- 1:nrow(predictiones_1.3)
predictiones_2.1$ID <- 1:nrow(predictiones_2.1)
predictiones_2.2$ID <- 1:nrow(predictiones_2.2)
predictiones_2.3$ID <- 1:nrow(predictiones_2.3)
subida <- merge(submission_template,predictiones_2.3, by="ID")
subidafinal = subset(subida, select = -c(ID,price) )
colnames(subidafinal)[2]="price"
write.csv(subidafinal,file='subida23.csv', row.names=FALSE)
##Modelo
lambda = .7
# Ridge
ridge_spec <- linear_reg(penalty = lambda, mixture = 1) %>%
set_engine("glmnet")
# Lasso
lasso_spec <- linear_reg(penalty = lambda, mixture = 0) %>%
set_engine("glmnet")
# Elastic Net (se especifica el parámetro de mixture entre 0 y 1)
# Tomemos un valor de 0.5 para empezar
elastic_net_spec <- linear_reg(penalty = lambda, mixture = .5) %>%
set_engine("glmnet")
# Primera receta
rec_1 <- recipe(price ~ total_rooms +surface_total + bathrooms + bedrooms + property_type + distancia_universidades +
distancia_bus + distancia_teatros + distancia_policia + distancia_concesionarios +
distancia_banco + distancia_gasolina + distancia_comercial + distancia_talleres +
distancia_parque , data = db) %>%
step_interact(terms = ~ total_rooms:bedrooms+bathrooms:property_type) %>%
step_novel(all_nominal_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
# Segunda receta
rec_2 <- recipe(price ~ total_rooms + surface_total+ bathrooms + bedrooms + property_type + parqueadero + area_universidades +
area_comercial + area_parques + distancia_bus +  distancia_universidades +
distancia_bus + distancia_teatros + distancia_policia , data = db) %>%
step_interact(terms = ~ total_rooms:bedrooms+bathrooms:property_type) %>%
step_novel(all_nominal_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
##Preguntas_______
train_2 <- as.data.frame(lapply(train_2, as.double))
test_2 <- as.data.frame(lapply(test_2, as.double))
# Crear un flujo de trabajo que incluye la receta de preprocesamiento y el modelo
workflow_1.1 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(ridge_spec)
workflow_1.2 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(lasso_spec)
workflow_1.3 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(elastic_net_spec)
workflow_2.1 <- workflow() %>%
add_recipe(rec_2) %>%
add_model(ridge_spec)
workflow_2.2 <- workflow() %>%
add_recipe(rec_2) %>%
add_model(lasso_spec)
workflow_2.3 <- workflow() %>%
add_recipe(rec_2) %>%
add_model(elastic_net_spec)
# Entrenamos el primer modelo con los datos de train
fit_1.1 <- workflow_1.1 %>%
fit(data = train_2)
fit_1.2 <- workflow_1.2 %>%
fit(data = train_2)
fit_1.3 <- workflow_1.3 %>%
fit(data = train_2)
fit_2.1 <- workflow_1.1 %>%
fit(data = train_2)
fit_2.2 <- workflow_2.2 %>%
fit(data = train_2)
fit_2.3 <- workflow_1.1 %>%
fit(data = train_2)
# Sacamos las predicciones sobre los datos de test
predictiones_1.1 <- predict(fit_1.1 , new_data = test_2)
predictiones_1.2 <- predict(fit_1.2 , new_data = test_2)
predictiones_1.3 <- predict(fit_1.3, new_data = test_2)
predictiones_2.1 <- predict(fit_2.1 , new_data = test_2)
predictiones_2.2 <- predict(fit_2.2, new_data = test_2)
predictiones_2.3 <- predict(fit_2.3, new_data = test_2)
submission_template$ID <- 1:nrow(submission_template)
predictiones_1.1$ID <- 1:nrow(predictiones_1.1)
predictiones_1.2$ID <- 1:nrow(predictiones_1.2)
predictiones_1.3$ID <- 1:nrow(predictiones_1.3)
predictiones_2.1$ID <- 1:nrow(predictiones_2.1)
predictiones_2.2$ID <- 1:nrow(predictiones_2.2)
predictiones_2.3$ID <- 1:nrow(predictiones_2.3)
subida <- merge(submission_template,predictiones_2.3, by="ID")
subidafinal = subset(subida, select = -c(ID,price) )
colnames(subidafinal)[2]="price"
write.csv(subidafinal,file='subida24.csv', row.names=FALSE)
lm(price ~ total_rooms + surface_total+ bathrooms + bedrooms + property_type + parqueadero + area_universidades +
area_comercial + area_parques + distancia_bus +  distancia_universidades +
distancia_bus + distancia_teatros + distancia_policia , data = db)
lm(price ~ total_rooms +surface_total + bathrooms + bedrooms + property_type + distancia_universidades +
distancia_bus + distancia_teatros + distancia_policia + distancia_concesionarios +
distancia_banco + distancia_gasolina + distancia_comercial + distancia_talleres +
distancia_parque , data = db)
mod<-lm(price ~ total_rooms +surface_total + bathrooms + bedrooms + property_type + distancia_universidades +
distancia_bus + distancia_teatros + distancia_policia + distancia_concesionarios +
distancia_banco + distancia_gasolina + distancia_comercial + distancia_talleres +
distancia_parque , data = db)
summary(mod)
mod<- lm(price ~ total_rooms +surface_total + bathrooms + bedrooms + property_type + distancia_universidades +
distancia_bus  + distancia_policia + distancia_concesionarios +
distancia_banco + distancia_talleres +
distancia_parque , data = db)
summary(mod)
View(db)
summary(db$surface_total)
mod <- lm(price ~ total_rooms + surface_total+ bathrooms + bedrooms + property_type + parqueadero + area_universidades +
area_comercial + area_parques + distancia_bus +  distancia_universidades +
distancia_bus + distancia_teatros + distancia_policia , data = db)
summary(mod)
mod <-lm(price ~ total_rooms + surface_total+ surface_covered+ bathrooms + bedrooms + property_type + parqueadero + area_universidades +
area_comercial + area_parques + distancia_bus +  distancia_universidades +
distancia_bus + distancia_teatros + distancia_policia , data = db)
summary(mod)
mod<- lm(price ~ total_rooms +surface_total+ surface_covered + bathrooms + bedrooms + property_type + distancia_universidades +
distancia_bus  + distancia_policia + distancia_concesionarios +
distancia_banco + distancia_talleres +
distancia_parque , data = db)
summary(price ~ total_rooms +surface_total+ surface_covered + bathrooms + bedrooms + property_type + distancia_universidades +
distancia_bus  + distancia_policia + distancia_concesionarios +
distancia_banco + distancia_talleres +
distancia_parque , data = db)
summary(mod)
##Modelo
lambda = .7
# Ridge
ridge_spec <- linear_reg(penalty = lambda, mixture = 1) %>%
set_engine("glmnet")
# Lasso
lasso_spec <- linear_reg(penalty = lambda, mixture = 0) %>%
set_engine("glmnet")
# Elastic Net (se especifica el parámetro de mixture entre 0 y 1)
# Tomemos un valor de 0.5 para empezar
elastic_net_spec <- linear_reg(penalty = lambda, mixture = .5) %>%
set_engine("glmnet")
# Primera receta
rec_1 <- recipe(price ~ total_rooms +surface_total+ surface_covered + bathrooms + bedrooms + property_type + distancia_universidades +
distancia_bus  + distancia_policia + distancia_concesionarios + distancia_parque , data = db) %>%
step_interact(terms = ~ total_rooms:bedrooms+bathrooms:property_type) %>%
step_novel(all_nominal_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
# Segunda receta
rec_2 <- recipe(price ~ total_rooms + surface_total + surface_covered + bathrooms + bedrooms + property_type + area_universidades +
area_comercial + area_parques + distancia_bus  +
distancia_bus + distancia_policia , data = db) %>%
step_interact(terms = ~ total_rooms:bedrooms+bathrooms:property_type) %>%
step_novel(all_nominal_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
##Preguntas_______
train_2 <- as.data.frame(lapply(train_2, as.double))
test_2 <- as.data.frame(lapply(test_2, as.double))
# Crear un flujo de trabajo que incluye la receta de preprocesamiento y el modelo
workflow_1.1 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(ridge_spec)
workflow_1.2 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(lasso_spec)
workflow_1.3 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(elastic_net_spec)
workflow_2.1 <- workflow() %>%
add_recipe(rec_2) %>%
add_model(ridge_spec)
workflow_2.2 <- workflow() %>%
add_recipe(rec_2) %>%
add_model(lasso_spec)
workflow_2.3 <- workflow() %>%
add_recipe(rec_2) %>%
add_model(elastic_net_spec)
# Entrenamos el primer modelo con los datos de train
fit_1.1 <- workflow_1.1 %>%
fit(data = train_2)
# Primera receta
rec_1 <- recipe(price ~ total_rooms +surface_total + bathrooms + bedrooms + property_type + distancia_universidades +
distancia_bus  + distancia_policia + distancia_concesionarios + distancia_parque , data = db) %>%
step_interact(terms = ~ total_rooms:bedrooms+bathrooms:property_type) %>%
step_novel(all_nominal_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
# Segunda receta
rec_2 <- recipe(price ~ total_rooms + surface_total + bathrooms + bedrooms + property_type + area_universidades +
area_comercial + area_parques + distancia_bus  +
distancia_bus + distancia_policia , data = db) %>%
step_interact(terms = ~ total_rooms:bedrooms+bathrooms:property_type) %>%
step_novel(all_nominal_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
##Preguntas_______
train_2 <- as.data.frame(lapply(train_2, as.double))
test_2 <- as.data.frame(lapply(test_2, as.double))
# Crear un flujo de trabajo que incluye la receta de preprocesamiento y el modelo
workflow_1.1 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(ridge_spec)
workflow_1.2 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(lasso_spec)
workflow_1.3 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(elastic_net_spec)
workflow_2.1 <- workflow() %>%
add_recipe(rec_2) %>%
add_model(ridge_spec)
workflow_2.2 <- workflow() %>%
add_recipe(rec_2) %>%
add_model(lasso_spec)
workflow_2.3 <- workflow() %>%
add_recipe(rec_2) %>%
add_model(elastic_net_spec)
# Entrenamos el primer modelo con los datos de train
fit_1.1 <- workflow_1.1 %>%
fit(data = train_2)
fit_1.2 <- workflow_1.2 %>%
fit(data = train_2)
fit_1.3 <- workflow_1.3 %>%
fit(data = train_2)
fit_2.1 <- workflow_1.1 %>%
fit(data = train_2)
fit_2.2 <- workflow_2.2 %>%
fit(data = train_2)
fit_2.3 <- workflow_1.1 %>%
fit(data = train_2)
# Sacamos las predicciones sobre los datos de test
predictiones_1.1 <- predict(fit_1.1 , new_data = test_2)
predictiones_1.2 <- predict(fit_1.2 , new_data = test_2)
predictiones_1.3 <- predict(fit_1.3, new_data = test_2)
predictiones_2.1 <- predict(fit_2.1 , new_data = test_2)
predictiones_2.2 <- predict(fit_2.2, new_data = test_2)
predictiones_2.3 <- predict(fit_2.3, new_data = test_2)
submission_template$ID <- 1:nrow(submission_template)
predictiones_1.1$ID <- 1:nrow(predictiones_1.1)
predictiones_1.2$ID <- 1:nrow(predictiones_1.2)
predictiones_1.3$ID <- 1:nrow(predictiones_1.3)
predictiones_2.1$ID <- 1:nrow(predictiones_2.1)
predictiones_2.2$ID <- 1:nrow(predictiones_2.2)
predictiones_2.3$ID <- 1:nrow(predictiones_2.3)
subida <- merge(submission_template,predictiones_2.3, by="ID")
subidafinal = subset(subida, select = -c(ID,price) )
colnames(subidafinal)[2]="price"
write.csv(subidafinal,file='subida24.csv', row.names=FALSE)
##Modelo
lambda = .7
# Ridge
ridge_spec <- linear_reg(penalty = lambda, mixture = 1) %>%
set_engine("glmnet")
# Lasso
lasso_spec <- linear_reg(penalty = lambda, mixture = 0) %>%
set_engine("glmnet")
# Elastic Net (se especifica el parámetro de mixture entre 0 y 1)
# Tomemos un valor de 0.5 para empezar
elastic_net_spec <- linear_reg(penalty = lambda, mixture = .5) %>%
set_engine("glmnet")
# Primera receta
rec_1 <- recipe(price ~ total_rooms +surface_total + bathrooms + bedrooms + property_type + distancia_universidades +
distancia_bus  + distancia_policia + distancia_concesionarios + distancia_parque , data = db) %>%
step_interact(terms = ~ total_rooms:bedrooms+bathrooms:property_type) %>%
step_novel(all_nominal_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
# Segunda receta
rec_2 <- recipe(price ~ total_rooms + surface_total + bathrooms + bedrooms + property_type + area_universidades +
area_comercial + area_parques + distancia_bus  +
distancia_bus + distancia_policia , data = db) %>%
step_interact(terms = ~ total_rooms:bedrooms+bathrooms:property_type) %>%
step_novel(all_nominal_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
##Preguntas_______
train_2 <- as.data.frame(lapply(train_2, as.double))
test_2 <- as.data.frame(lapply(test_2, as.double))
# Crear un flujo de trabajo que incluye la receta de preprocesamiento y el modelo
workflow_1.1 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(ridge_spec)
workflow_1.2 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(lasso_spec)
workflow_1.3 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(elastic_net_spec)
workflow_2.1 <- workflow() %>%
add_recipe(rec_2) %>%
add_model(ridge_spec)
workflow_2.2 <- workflow() %>%
add_recipe(rec_2) %>%
add_model(lasso_spec)
workflow_2.3 <- workflow() %>%
add_recipe(rec_2) %>%
add_model(elastic_net_spec)
# Entrenamos el primer modelo con los datos de train
fit_1.1 <- workflow_1.1 %>%
fit(data = train_2)
fit_1.2 <- workflow_1.2 %>%
fit(data = train_2)
fit_1.3 <- workflow_1.3 %>%
fit(data = train_2)
fit_2.1 <- workflow_1.1 %>%
fit(data = train_2)
fit_2.2 <- workflow_2.2 %>%
fit(data = train_2)
fit_2.3 <- workflow_1.1 %>%
fit(data = train_2)
# Sacamos las predicciones sobre los datos de test
predictiones_1.1 <- predict(fit_1.1 , new_data = test_2)
predictiones_1.2 <- predict(fit_1.2 , new_data = test_2)
predictiones_1.3 <- predict(fit_1.3, new_data = test_2)
predictiones_2.1 <- predict(fit_2.1 , new_data = test_2)
predictiones_2.2 <- predict(fit_2.2, new_data = test_2)
predictiones_2.3 <- predict(fit_2.3, new_data = test_2)
submission_template$ID <- 1:nrow(submission_template)
predictiones_1.1$ID <- 1:nrow(predictiones_1.1)
predictiones_1.2$ID <- 1:nrow(predictiones_1.2)
predictiones_1.3$ID <- 1:nrow(predictiones_1.3)
predictiones_2.1$ID <- 1:nrow(predictiones_2.1)
predictiones_2.2$ID <- 1:nrow(predictiones_2.2)
predictiones_2.3$ID <- 1:nrow(predictiones_2.3)
subida <- merge(submission_template,predictiones_2.3, by="ID")
subidafinal = subset(subida, select = -c(ID,price) )
colnames(subidafinal)[2]="price"
write.csv(subidafinal,file='subida25.csv', row.names=FALSE)
