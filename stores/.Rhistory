group_by(`Pais Origen`, `TIPO PRODUCTO`, `Fecha aaaa-mm` = format(Fecha, "%Y-%m")) %>%
summarise(
Valor_FOB_Acumulado = sum(Valor_FOB),
Cantidad_Acumulada = sum(Cantidad)
)
# Calcular el valor de importaciones
resultados <- Ecuador_Total_filtrado %>%
group_by(`Pais Origen`, `TIPO PRODUCTO`, Mes = format(Fecha, "%Y-%m")) %>%
summarise(
Valor_FOB_Acumulado = sum(Valor_FOB),
Cantidad_Acumulada = sum(Cantidad)
)
# Calcular el valor de importaciones
resultados <- Ecuador_Total_filtrado %>%
group_by(`Pais Origen`, `TIPO PRODUCTO`, Mes = format(Fecha aaaa-mm, "%Y-%m")) %>%
# Calcular el valor de importaciones
resultados <- Ecuador_Total_filtrado %>%
group_by(`Pais Origen`, `TIPO PRODUCTO`, Mes = format(Fecha aaaa-mm, "%Y-%m")) %>%
# Calcular el valor de importaciones
Ecuador_Total_filtrado <- Ecuador_Total_filtrado %>%
rename(Fecha = `Fecha aaaa-mm`)
resultados <- Ecuador_Total_filtrado %>%
group_by(`Pais Origen`, `TIPO PRODUCTO`, Mes = format(Fecha, "%Y-%m")) %>%
summarise(
Valor_FOB_Acumulado = sum(Valor_FOB),
Cantidad_Acumulada = sum(Cantidad)
)
Ecuador_Total_filtrado <- Ecuador_Total_filtrado %>%
filter(!is.na(Fecha))
resultados <- Ecuador_Total_filtrado %>%
group_by(`Pais Origen`, `TIPO PRODUCTO`, Mes = format(Fecha, "%Y-%m")) %>%
summarise(
Valor_FOB_Acumulado = sum(Valor_FOB),
Cantidad_Acumulada = sum(Cantidad)
)
resultados <- Ecuador_Total_filtrado %>%
group_by(`Pais Origen`, `TIPO PRODUCTO`, Mes = format(Fecha, "%Y-%m")) %>%
summarise(
Valor_FOB_Acumulado = sum(Valor_FOB),
Cantidad_Acumulada = sum(Cantidad)
)
resultados <- Ecuador_Total_filtrado %>%
group_by(`Pais Origen`, `TIPO PRODUCTO`, Mes = format(Fecha, "%Y-%m")) %>%
summarise(
Valor_FOB_Acumulado = sum(Valor_FOB),
Cantidad_Acumulada = sum(Cantidad)
)
Ecuador_Total_filtrado$Fecha <- as.Date(Ecuador_Total_filtrado$Fecha, format = "%Y-%m")
resultados <- Ecuador_Total_filtrado %>%
group_by(`Pais Origen`, `TIPO PRODUCTO`, Mes = format(Fecha, "%Y-%m")) %>%
summarise(
Valor_FOB_Acumulado = sum(Valor_FOB),
Cantidad_Acumulada = sum(Cantidad)
)
resultados <- Ecuador_Total_filtrado %>%
group_by(`Pais Origen`, `TIPO PRODUCTO`, Fecha = format(Fecha, "%Y-%m")) %>%
summarise(
Valor_FOB_Acumulado = sum(Valor_FOB),
Cantidad_Acumulada = sum(Cantidad)
)
resultados <- Ecuador_Total_filtrado %>%
group_by(`Pais Origen`, `TIPO PRODUCTO`, Mes = format(Fecha, "%Y-%m")) %>%
summarise(
Valor_FOB_Acumulado = sum(Valor_FOB),
Cantidad_Acumulada = sum(Cantidad)
)
#Proceso Analista Económico Junior en EConcept AEI - Examen Jueves#####
###Erick Julian Villabon
# Limpiar el environment y el panel
rm(list = ls())
cat("\014")
# Cargamos los paquetes
if(!require(pacman))install.packages("pacman") ; require(pacman)
require(pacman)
p_load(rio, tidyverse, readxl, ggplot2, skimr, openxlsx)
# Cargamos las bases de datos
Ecuador_Enero_Febrero <- read_excel("C:/Users/Erick/Desktop/Proceso_Analista_EConcept/Ecuador Enero Febrero.xlsx")
Ecuador_Febrero_Marzo <- read_excel("C:/Users/Erick/Desktop/Proceso_Analista_EConcept/Ecuador Febrero Marzo.xlsx")
Ecuador_Marzo_Abril <- read_excel("C:/Users/Erick/Desktop/Proceso_Analista_EConcept/Ecuador Marzo Abril.xlsx")
Ecuador_Mayo_Junio <- read_excel("C:/Users/Erick/Desktop/Proceso_Analista_EConcept/Ecuador Mayo Junio.xlsx")
# Unimos las bases
Ecuador_Total <- rbind(Ecuador_Enero_Febrero, Ecuador_Febrero_Marzo, Ecuador_Marzo_Abril, Ecuador_Mayo_Junio)
# Creamos tipo de columna
Ecuador_Total <- Ecuador_Total %>%
mutate(
`TIPO PRODUCTO` = case_when(
grepl("LAPTOP|COMPUTADORA", tolower(`Descripcion Comercial del Producto`)) ~ "Computadores portátiles",
grepl("TABLETS|IPAD", tolower(`Descripcion Comercial del Producto`)) ~ "Tablets",
TRUE ~ "Otros"
)
)
# Seleccionar solo los países
Ecuador_Total_filtrado <- Ecuador_Total %>%
filter(`Pais Origen` %in% c("ESTADOS UNIDOS", "CHINA", "HONG KONG", "ESPAÑA", "MEXICO"))
# Calcular el valor de importaciones
Ecuador_Total_filtrado <- Ecuador_Total_filtrado %>%
rename(Fecha = `Fecha aaaa-mm`)
Ecuador_Total_filtrado <- Ecuador_Total_filtrado %>%
filter(!is.na(Fecha))
Ecuador_Total_filtrado$Fecha <- as.Date(Ecuador_Total_filtrado$Fecha, format = "%Y-%m")
#Proceso Analista Económico Junior en EConcept AEI - Examen Jueves#####
###Erick Julian Villabon
# Limpiar el environment y el panel
rm(list = ls())
cat("\014")
# Cargamos los paquetes
if(!require(pacman))install.packages("pacman") ; require(pacman)
require(pacman)
p_load(rio, tidyverse, readxl, ggplot2, skimr, openxlsx)
# Cargamos las bases de datos
Ecuador_Enero_Febrero <- read_excel("C:/Users/Erick/Desktop/Proceso_Analista_EConcept/Ecuador Enero Febrero.xlsx")
Ecuador_Febrero_Marzo <- read_excel("C:/Users/Erick/Desktop/Proceso_Analista_EConcept/Ecuador Febrero Marzo.xlsx")
Ecuador_Marzo_Abril <- read_excel("C:/Users/Erick/Desktop/Proceso_Analista_EConcept/Ecuador Marzo Abril.xlsx")
Ecuador_Mayo_Junio <- read_excel("C:/Users/Erick/Desktop/Proceso_Analista_EConcept/Ecuador Mayo Junio.xlsx")
# Unimos las bases
Ecuador_Total <- rbind(Ecuador_Enero_Febrero, Ecuador_Febrero_Marzo, Ecuador_Marzo_Abril, Ecuador_Mayo_Junio)
# Creamos tipo de columna
Ecuador_Total <- Ecuador_Total %>%
mutate(
`TIPO PRODUCTO` = case_when(
grepl("LAPTOP|COMPUTADORA", tolower(`Descripcion Comercial del Producto`)) ~ "Computadores portátiles",
grepl("TABLETS|IPAD", tolower(`Descripcion Comercial del Producto`)) ~ "Tablets",
TRUE ~ "Otros"
)
)
# Seleccionar solo los países
Ecuador_Total_filtrado <- Ecuador_Total %>%
filter(`Pais Origen` %in% c("ESTADOS UNIDOS", "CHINA", "HONG KONG", "ESPAÑA", "MEXICO"))
# Calcular el valor de importaciones
Ecuador_Total_filtrado <- Ecuador_Total_filtrado %>%
rename(Fecha = `Fecha aaaa-mm`)
Ecuador_Total_filtrado <- Ecuador_Total_filtrado %>%
filter(!is.na(Fecha))
resultados <- Ecuador_Total_filtrado %>%
group_by(`Pais Origen`, `TIPO PRODUCTO`, Mes = format(Fecha, "%Y-%m")) %>%
summarise(
Valor_FOB_Acumulado = sum(Valor_FOB),
Cantidad_Acumulada = sum(Cantidad)
)
resultados <- Ecuador_Total_filtrado %>%
group_by(`Pais Origen`, `TIPO PRODUCTO`, `Fecha`) %>%
summarise(
Valor_FOB_Acumulado = sum(Valor_FOB),
Cantidad_Acumulada = sum(Cantidad)
)
Ecuador_Total_filtrado <- Ecuador_Total_filtrado %>%
rename(Valor_FOB = `TOTAL VALOR FOB (US$)`)
Ecuador_Total_filtrado <- Ecuador_Total_filtrado %>%
rename(Valor_FOB = `TOTAL VALOR FOB (US$)`)
require(pacman)
## Llama/instala-llama las librerías listadas
p_load(tidyverse,rio,skimr,
viridis, # paletas de colores
sf, # Leer/escribir/manipular datos espaciales
leaflet, # Visualizaciones dinámicas
tmaptools, # geocode_OSM()
osmdata) # Get OSM's data
## Llama/instala-llama las librerías listadas
p_load(tidyverse,rio,skimr,
viridis, # paletas de colores
sf, # Leer/escribir/manipular datos espaciales
leaflet, # Visualizaciones dinámicas
tmaptools, # geocode_OSM()
osmdata) # Get OSM's data
geocode_OSM("Casa de Nariño, Bogotá")
geocode_OSM("Casa de Nariño, Bogotá")
geocode_OSM("Casa de Nariño, Bogotá")
require(pacman)
p_load(tidyverse,rio,skimr,
viridis, # paletas de colores
sf, # Leer/escribir/manipular datos espaciales
leaflet, # Visualizaciones dinámicas
tmaptools, # geocode_OSM()
osmdata) # Get OSM's data
geocode_OSM("Casa de Nariño, Bogotá")
ggmap("Casa de Nariño, Bogotá")
osmdata("Casa de Nariño, Bogotá")
osmdata("Casa de Narino, Bogota")
osmdata("Casa de Narino, Bogota")
ggmap("Plaza de Bolivar, Bogotá")
geocode_OSM("Plaza de Bolivar, Bogotá")
geocode_OSM("Casa de Nariño (Presidencia de la República)")
Plaza de Bolivar, Bogotá
geocode_OSM("Casa de Nariño, Bogotá")
require(pacman)
p_load(tidyverse,rio,skimr,
viridis, # paletas de colores
sf, # Leer/escribir/manipular datos espaciales
leaflet, # Visualizaciones dinámicas
tmaptools, # geocode_OSM()
osmdata) # Get OSM's data
geocode_OSM("Casa de Nariño, Bogotá")
cbd <- geocode_OSM("Centro Internacional, Bogotá", as.sf=T)
cbd
geocode_OSM("Casa de Nariño, Bogotá")
rm(list = ls())
# - Librerias y paquetes
library(pacman)
p_load(rvest, tidyverse, ggplot2, robotstxt, psych, stargazer, boot, plotly, openxlsx, glmnet,
rio, leaflet, rgeos, modeldata, vtable, tmaptools, sf, osmdata, tidymodels, writexl,
units, randomForest, rattle, spatialsample, xgboost)
# - Revisar el espacio de trabajo
#setwd("/Users/juandiego/Desktop/GitHub/Problem_Set_2/stores")
setwd("E:/Problem_Set_2/stores")
#___________________________________________________________
#
#                PREDUCCIONES
#
#___________________________________________________________
#___________________________________________________________
# - Limpiar espacio de trabajo
rm(list = ls())
# - Librerias y paquetes
library(pacman)
p_load(rvest, tidyverse, ggplot2, robotstxt, psych, stargazer, boot, plotly, openxlsx, glmnet,
rio, leaflet, rgeos, modeldata, vtable, tmaptools, sf, osmdata, tidymodels, writexl,
units, randomForest, rattle, spatialsample, xgboost)
# - Revisar el espacio de trabajo
#setwd("/Users/juandiego/Desktop/GitHub/Problem_Set_2/stores")
setwd("E:/Problem_Set_2/stores")
#___________________________________________________________
#
#                PREDUCCIONES
#
#___________________________________________________________
#___________________________________________________________
# - Limpiar espacio de trabajo
rm(list = ls())
# - Librerias y paquetes
library(pacman)
p_load(rvest, tidyverse, ggplot2, robotstxt, psych, stargazer, boot, plotly, openxlsx, glmnet,
rio, leaflet, rgeos, modeldata, vtable, tmaptools, sf, osmdata, tidymodels, writexl,
units, randomForest, rattle, spatialsample, xgboost)
# - Revisar el espacio de trabajo
#setwd("/Users/juandiego/Desktop/GitHub/Problem_Set_2/stores")
#setwd("E:/Problem_Set_2/stores")
setwd("C:/Users/Erick/Desktop/Problem_Set_2/stores")
getwd()
list.files()
# 1. Importar las bases de datos ya preparadas enteriormente
test <- read.xlsx("test_2.xlsx")
train <- read.xlsx("train_2.xlsx")
submission_template <- read.csv("submission_template.csv")
db <- read.xlsx("db.xlsx")
sapply(db,function(x) sum(is.na(x)))
db<- db %>% mutate(areaxparques=area_parques*distancia_parque)
train<- train %>% mutate(areaxparques=area_parques*distancia_parque)
test<- test %>% mutate(areaxparques=area_parques*distancia_parque)
db<- db %>% mutate(areaxuniversidades=area_universidades*distancia_universidades)
train<- train %>% mutate(areaxuniversidades=area_universidades*distancia_universidades)
test<- test %>% mutate(areaxuniversidades=area_universidades*distancia_universidades)
db<- db %>% mutate(areaxcomerciales=area_comercial*distancia_comercial)
train<- train %>% mutate(areaxcomerciales=area_comercial*distancia_comercial)
test<- test %>% mutate(areaxcomerciales=area_comercial*distancia_comercial)
db<- db %>% mutate(bedroomxbathroom =bathrooms*bedrooms)
train<- train %>% mutate(bedroomxbathroom =bathrooms*bedrooms)
test<- test %>% mutate(bedroomxbathroom =bathrooms*bedrooms)
db<- db %>% mutate(distancia_bus_2 =distancia_bus*distancia_bus)
train<- train %>% mutate(distancia_bus_2 =distancia_bus*distancia_bus)
test<- test %>% mutate(distancia_bus_2 =distancia_bus*distancia_bus)
db<- db %>% mutate(estratoxrooms =estrato*bedrooms)
train<- train %>% mutate(estratoxrooms =estrato*bedrooms)
test<- test %>% mutate(estratoxrooms =estrato*bedrooms)
##________________________________________________________________________
#
#                            Modelo Líneal
#
##________________________________________________________________________
#Modelo 1
rec_1 <- recipe(price ~ surface_total + bathrooms + bedrooms + property_type +
distancia_universidades + distancia_bus  + distancia_policia +
distancia_concesionarios + distancia_parque + estrato, data = db)%>%
step_dummy(all_nominal_predictors())
reglineal<-linear_reg()
workf_1<-workflow() %>%
add_recipe(rec_1) %>%
add_model(reglineal)
fit_1 <- workf_1 %>%
fit(data=train)
y1 <- predict(fit_1, new_data = test) %>%
bind_cols(test)
y1<- y1 %>%
select(property_id, .pred)
colnames(y1)[".pred"] <- "price"
y1$price <- y1$.pred
y1 <- y1[, -which(names(y1) == ".pred")]
write.table(y1, file = "ML_1.csv", sep = ",", row.names = FALSE, col.names = TRUE)
##________________________________________________________________________
#
#                      Regularización de Modelos Lineales
#
##________________________________________________________________________
#reg1 <- lm(price ~ surface_total + bathrooms + bedrooms + property_type +
#                 distancia_universidades + distancia_bus  + distancia_policia +
#                 distancia_concesionarios + distancia_parque + estrato, data = db)
#stargazer(reg1,type="text")
# encontrar el lambda optimo
train_fold <- vfold_cv(train, v = 30)
# Primera receta
#rec_1 <- recipe(price ~ surface_total + bathrooms + bedrooms + property_type + area_universidades +
#                  area_comercial + area_parques + distancia_bus  +
#                  distancia_bus + distancia_policia + estrato , data = db) %>%
#  step_interact(terms = ~ estrato:bedrooms+bathrooms:property_type) %>%
#  step_novel(all_nominal_predictors()) %>%
#  step_dummy(all_nominal_predictors()) %>%
#  step_zv(all_predictors()) %>%
#  step_normalize(all_predictors())
rec_1 <- recipe(price ~ rooms + bathrooms + bedrooms + parqueadero + property_type +
area_comercial + distancia_bus + areaxparques + distancia_bus_2 + surface_total
+ parqueadero + nuevo + distancia_parque + distancia_universidades + estrato + estratoxrooms, data = db) %>%
step_interact(terms = ~ bathrooms:rooms+bedrooms:rooms) %>%
step_novel(all_nominal_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors())
# Ridge
ridge_spec <- linear_reg(penalty = tune(), mixture = 1) %>%
set_mode("regression") %>%
set_engine("glmnet")
# Lasso
lasso_spec <- linear_reg(penalty = tune(), mixture = 0) %>%
set_mode("regression") %>%
set_engine("glmnet")
# Elastic Net
elastic_net_spec <- linear_reg(penalty = tune(), mixture = .5) %>%
set_mode("regression") %>%
set_engine("glmnet")
# Workflows
workflow_1.1 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(ridge_spec)
workflow_1.2 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(lasso_spec)
workflow_1.3 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(elastic_net_spec)
# Penalización
penalty_grid <- grid_regular(penalty(range = c(-4, 4)), levels = 30)
penalty_grid
tune_res1 <- tune_grid(
workflow_1.1,
resamples = train_fold,
grid = penalty_grid,
metrics = metric_set(rmse)
)
tune_res2 <- tune_grid(
workflow_1.2,
resamples = train_fold,
grid = penalty_grid,
metrics = metric_set(rmse)
)
tune_res3 <- tune_grid(
workflow_1.3,
resamples = train_fold,
grid = penalty_grid,
metrics = metric_set(rmse)
)
# Seleccionar el mejor valor de penalización
best_penalty1 <- select_best(tune_res1, metric = "rmse")
best_penalty2 <- select_best(tune_res2, metric = "rmse")
best_penalty3 <- select_best(tune_res3, metric = "rmse")
modelo_1.1 <- finalize_workflow(workflow_1.1, best_penalty1)
modelo_1.2 <- finalize_workflow(workflow_1.2, best_penalty2)
modelo_1.3 <- finalize_workflow(workflow_1.3, best_penalty3)
# Entrenamos el primer modelo con los datos de train
fit_1.1 <- fit(modelo_1.1, data = train)
fit_1.2 <- fit(modelo_1.2, data = train)
fit_1.3 <- fit(modelo_1.3, data = train)
# Evaluacipon del modelo
augment(fit_1.1, new_data = train) %>%
mae(truth = price, estimate = .pred)
augment(fit_1.2, new_data = train) %>%
mae(truth = price, estimate = .pred)
augment(fit_1.3, new_data = train) %>%
mae(truth = price, estimate = .pred)
# Sacamos las predicciones sobre los datos de test
predictiones_1.1 <- predict(fit_1.1 , new_data = test)
subida <- data.frame(
property_id = submission_template$property_id,
.price = predictiones_1.1
)
colnames(subida)[2]<-"price"
write.csv(subida,file='Ridge_2.csv', row.names=FALSE)
predictiones_1.2 <- predict(fit_1.2 , new_data = test)
subida <- data.frame(
property_id = submission_template$property_id,
.price = predictiones_1.2
)
colnames(subida)[2]<-"price"
write.csv(subida,file='Lasso_2.csv', row.names=FALSE)
predictiones_1.3 <- predict(fit_1.3, new_data = test)
subida <- data.frame(
property_id = submission_template$property_id,
.price = predictiones_1.3
)
colnames(subida)[2]<-"price"
write.csv(subida,file='Elastic_Net_2.csv', row.names=FALSE)
##________________________________________________________________________
#
#                                 Arboles
#
##________________________________________________________________________
# Tune grid aleatorio para el modelo de árboles
tune_grid_tree <- grid_random(
tree_depth(range = c(1, 10)),
min_n(range = c(1, 20)),
size = 5
)
## Modelo de arboles
tree_spec <- decision_tree(
tree_depth = tune(),
min_n = tune()
) %>%
set_mode("regression")
# Tune grid aleatorio para el modelo de rf
rf_grid_random <- grid_random(  mtry(range = c(2, 4)),
min_n(range = c(1, 10)),
trees(range = c(100, 300)), size = 4)
# Agregar modelos basados en árboles
# Random Forest
# Modelo de rf
rf_spec<- rand_forest(
mtry = tune(),
min_n = tune(),
trees = tune(),
) %>%
set_engine("randomForest") %>%
set_mode("regression")
# Tune grid aleatorio para el modelo de boost
tune_grid_boost <- grid_random(
trees(range = c(400, 600)),
min_n(range = c(1, 3)),
learn_rate(range = c(0.001, 0.01)), size = 4
)
# Especificación del modelo boost_tree en tidymodels
boost_spec <- boost_tree(
trees = tune(),
min_n = tune(),
learn_rate = tune()
) %>%
set_mode("regression")
# Primera receta
rec_1 <- recipe(price ~ surface_total + bathrooms + bedrooms + property_type + area_universidades +
area_comercial + area_parques + distancia_bus  +
distancia_bus + distancia_policia + estrato , data = db) %>%
step_interact(terms = ~ estrato:bedrooms+bathrooms:property_type) %>%
step_novel(all_nominal_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
## para el caso de los arboles incorpora no linealidades.
workflow_1.1 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(tree_spec)
workflow_1.2 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(rf_spec)
workflow_1.3 <- workflow() %>%
add_recipe(rec_1) %>%
add_model(boost_spec)
# definimos nuestra variable como sf
train_sf <- st_as_sf(
train,
# "coords" is in x/y order -- so longitude goes first!
coords = c("lon", "lat"),
# Set our coordinate reference system to EPSG:4326,
# the standard WGS84 geodetic coordinate reference system
crs = 4326
)
# aplicamos la funcion spatial_block_cv
set.seed(12345)
block_folds <- spatial_block_cv(train_sf, v = 5)
autoplot(block_folds)
p_load("purrr")
walk(block_folds$splits, function(x) print(autoplot(x)))
# Esto se utilizará para evaluar el rendimiento del modelo en diferentes subconjuntos de  datos durante la validación cruzada.
df_fold <- vfold_cv(train, v = 3)
tune_tree <- tune_grid(
workflow_1.1,
resamples = block_folds,
grid = tune_grid_tree,
metrics = metric_set(mae)
)
tune_rf <- tune_grid(
workflow_1.2,
resamples = block_folds,
grid = rf_grid_random,
metrics = metric_set(mae)
)
tune_boost <- tune_grid(
workflow_1.3,
resamples = block_folds,
grid = tune_grid_boost,
metrics = metric_set(mae)
)
# Utilizar 'select_best' para seleccionar el mejor valor.
best_parms_tree <- select_best(tune_tree, metric = "mae")
best_parms_tree
# Utilizar 'select_best' para seleccionar el mejor valor.
best_parms_rf<- select_best(tune_rf, metric = "mae")
best_parms_rf
# Utilizar 'select_best' para seleccionar el mejor valor.
best_parms_boost <- select_best(tune_boost, metric = "mae")
best_parms_boost
# Finalizar el flujo de trabajo 'workflow' con el mejor valor de parametros
tree_final <- finalize_workflow(workflow_1.1, best_parms_tree)
# Ajustar el modelo  utilizando los datos de entrenamiento
tree_final_fit <- fit(tree_final, data = test)
# Finalizar el flujo de trabajo 'workflow' con el mejor valor de parametros
rf_final <- finalize_workflow(workflow_1.2, best_parms_rf)
# Ajustar el modelo utilizando los datos de entrenamiento
rf_final_fit <- fit(rf_final, data = test)
